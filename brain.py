import os
import base64
import json
try:
    import anthropic
except ImportError:
    anthropic = None
import streamlit as st

def get_anthropic_client():
    """×™×•×¦×¨ ×—×™×‘×•×¨ ×œ-Claude ×‘×¦×•×¨×” ×××•×‘×˜×—×ª ×¢× ×¢×“×™×¤×•×ª ×œ××©×ª× ×™ ×¡×‘×™×‘×”"""
    if anthropic is None:
        return None, "×¡×¤×¨×™×™×ª anthropic ×—×¡×¨×”."
    
    # 1. × ×™×¡×™×•×Ÿ ×œ××©×•×š ×××©×ª× ×™ ×¡×‘×™×‘×” (Render) - ×”×›×™ ×—×©×•×‘
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    
    # 2. ×× ××™×Ÿ, × ×™×¡×™×•×Ÿ ×œ××©×•×š ×-secrets (××§×•××™)
    if not api_key:
        try:
            api_key = st.secrets.get("ANTHROPIC_API_KEY")
        except Exception:
            pass
    
    if not api_key:
        return None, "×—×¡×¨ ××¤×ª×— API"
        
    return anthropic.Anthropic(api_key=api_key), None


def process_plan_metadata(raw_text):
    """
    âœ¨ ××©×•×œ×‘: ××—×œ×¥ ××˜×-×“××˜×” ××œ××” ×¢× ×¤×¨×•××¤×˜ ××§×™×£
    """
    client, error = get_anthropic_client()
    if error: 
        return {
            "status": "no_api_key",
            "error": error,
            "document": {},
            "rooms": [],
            "heights_and_levels": {},
            "execution_notes": {},
            "limitations": [error],
            "quantities_hint": {"wall_types_mentioned": [], "material_hints": []}
        }

    # ×¨×©×™××ª ××•×“×œ×™× ×œ× ×™×¡×™×•×Ÿ (××”×—×“×© ×œ×™×©×Ÿ)
    models = [
        "claude-3-5-sonnet-20241022",
        "claude-3-5-sonnet-20240620", 
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307"
    ]

    # ===== ×”×¤×¨×•××¤×˜ ×”××œ× =====
    prompt = f"""
××ª×” ××•××—×” ×‘×—×™×œ×•×¥ ××™×“×¢ ××ª×•×›× ×™×•×ª ×‘× ×™×” ×™×©×¨××œ×™×•×ª.
×”××©×™××”: ×œ×—×œ×¥ **×›×œ** ×”××™×“×¢ ×”×–××™×Ÿ ××”×˜×§×¡×˜ ×•×œ××¨×’×Ÿ ××•×ª×• ×‘-JSON ××•×‘× ×”.

**×—×©×•×‘ ×××•×“:**
- ×”×—×–×¨ **×¨×§** JSON ×ª×§×™×Ÿ, ×œ×œ× ×˜×§×¡×˜ × ×•×¡×£
- ×•×“× ×©××™×Ÿ ×¤×¡×™×§×™× ××™×•×ª×¨×™× ×œ×¤× ×™ ] ××• }}
- ×—×œ×¥ **×›×œ** ××™×“×¢ ×–××™×Ÿ, ×‘××™×•×—×“ **××™×“×•×ª ×—×“×¨×™×** ×•**×©×˜×—×™×**
- ×× ×™×© ×˜×§×¡×˜ ×—×•×–×¨ ××• OCR ×œ× ××•×©×œ× - × ×¡×” ×œ×”×‘×™×Ÿ ××ª ×”×›×•×•× ×”

**×˜×§×¡×˜ ××”×ª×•×›× ×™×ª:**
{raw_text[:3500]}

**××‘× ×” JSON × ×“×¨×©:**

{{
  "document": {{
    "plan_title": {{"value": "×©× ×”×ª×•×›× ×™×ª", "confidence": 0-100, "evidence": ["×¦×™×˜×•×˜"]}},
    "plan_type": {{"value": "×§×™×¨×•×ª/×ª×§×¨×”/×¨×™×¦×•×£/×—×©××œ", "confidence": 0-100, "evidence": []}},
    "scale": {{"value": "1:50", "confidence": 0-100, "evidence": []}},
    "date": {{"value": "2024-01-15", "confidence": 0-100, "evidence": []}},
    "floor_or_level": {{"value": "×§×•××” ×'", "confidence": 0-100, "evidence": []}},
    "project_name": {{"value": null, "confidence": 0, "evidence": []}},
    "project_address": {{"value": null, "confidence": 0, "evidence": []}},
    "architect_name": {{"value": null, "confidence": 0, "evidence": []}},
    "drawing_number": {{"value": null, "confidence": 0, "evidence": []}}
  }},
  "rooms": [
    {{
      "name": {{"value": "×—×“×¨ ×©×™× ×” 1", "confidence": 95, "evidence": ["×—×“×¨ ×©×™× ×” 1"]}},
      "area_m2": {{"value": 15.5, "confidence": 90, "evidence": ["15.5 ×\\"×¨"]}},
      "ceiling_height_m": {{"value": 2.70, "confidence": 85, "evidence": ["H=2.70"]}},
      "flooring_notes": {{"value": "×¤×¨×§×˜", "confidence": 80, "evidence": ["×¤×¨×§×˜"]}},
      "ceiling_notes": {{"value": null, "confidence": 0, "evidence": []}},
      "other_notes": {{"value": null, "confidence": 0, "evidence": []}}
    }}
  ],
  "heights_and_levels": {{
    "default_ceiling_height_m": {{"value": 2.80, "confidence": 70, "evidence": ["H=2.80"]}},
    "default_floor_height_m": {{"value": null, "confidence": 0, "evidence": []}},
    "construction_level_m": {{"value": null, "confidence": 0, "evidence": []}}
  }},
  "execution_notes": {{
    "general_notes": {{"value": null, "confidence": 0, "evidence": []}},
    "structural_notes": {{"value": null, "confidence": 0, "evidence": []}},
    "hvac_notes": {{"value": null, "confidence": 0, "evidence": []}},
    "electrical_notes": {{"value": null, "confidence": 0, "evidence": []}},
    "plumbing_notes": {{"value": null, "confidence": 0, "evidence": []}}
  }},
  "limitations": ["×¨×©×•× ×›××Ÿ ×‘×¢×™×•×ª/××’×‘×œ×•×ª ×× ×™×©"],
  "quantities_hint": {{
    "wall_types_mentioned": ["×§×™×¨ ×‘×˜×•×Ÿ 20 ×¡\\"×"],
    "material_hints": ["×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ"]
  }}
}}

**×—×™×¤×•×© ×—×“×¨×™×:**
- ×©××•×ª: "×—×“×¨ ×©×™× ×”", "×¡×œ×•×Ÿ", "××˜×‘×—", "×©×™×¨×•×ª×™×"
- ×©×˜×—×™×: "15 ×\\"×¨", "15.5 mÂ²", "15 sqm", ××• ××¡×¤×¨ ×œ×™×“ ×©× ×—×“×¨
- ×’×‘×”×™×: "H=2.80", "×’×•×‘×” 2.70", "ceiling height 2.80m"
- ×¨×™×¦×•×£: "×§×¨××™×§×”", "×¤×¨×§×˜", "×©×™×©", "×’×¨× ×™×˜"
- ×ª×§×¨×”: "×’×‘×¡", "×˜×¨×•×•×œ", "×ª×§×¨×” ××§×•×¡×˜×™×ª"

**×”×ª×—×œ - ×”×—×–×¨ ×¨×§ JSON:**
"""

    for model in models:
        try:
            message = client.messages.create(
                model=model,
                max_tokens=6000,
                messages=[{"role": "user", "content": prompt}]
            )
            
            response_text = message.content[0].text.strip()
            
            # × ×™×§×•×™
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()
            
            # ×—×™×œ×•×¥ JSON
            if "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                response_text = response_text[start:end]
            
            # ×¤×¨×¡×•×¨
            try:
                result = json.loads(response_text)
                result["status"] = "success"
                result["_model_used"] = model
                return result
            except json.JSONDecodeError:
                # ×ª×™×§×•×Ÿ ××•×˜×•××˜×™
                fixed = response_text.replace(",]", "]").replace(",}", "}")
                result = json.loads(fixed)
                result["status"] = "success"
                result["_model_used"] = model
                result["_auto_fixed"] = True
                return result
            
        except Exception as e:
            if "not_found_error" in str(e) or "404" in str(e):
                continue
            continue
    
    # ×›×©×œ×•×Ÿ ×‘×›×œ ×”××•×“×œ×™×
    return {
        "status": "extraction_failed",
        "error": "×›×œ ×”××•×“×œ×™× × ×›×©×œ×•",
        "document": {},
        "rooms": [],
        "heights_and_levels": {},
        "execution_notes": {},
        "limitations": ["Failed to extract data with all models"],
        "quantities_hint": {"wall_types_mentioned": [], "material_hints": []}
    }


def analyze_legend_image(image_bytes):
    """
    âœ¨ ××©×•×¤×¨: ×× ×ª×— ×ª××•× ×” ×©×œ ××§×¨× ×ª×•×›× ×™×ª ×‘× ×™×”
    ×¢× few-shot learning
    """
    client, error = get_anthropic_client()
    if error: return {"error": error}

    models = [
        "claude-3-5-sonnet-20241022",
        "claude-3-5-sonnet-20240620",
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307"
    ]

    encoded_image = base64.b64encode(image_bytes).decode('utf-8')
    
    prompt = """
××ª×” ××•××—×” ×‘× ×™×ª×•×— ×ª×•×›× ×™×•×ª ×‘× ×™×” ×™×©×¨××œ×™×•×ª.
× ×ª×— ××ª ×”××§×¨× (Legend) ×‘×ª××•× ×” ×–×•.

ğŸ“š **×“×•×’×××•×ª ×œ×œ××™×“×”:**

**×“×•×’××” 1 - ×ª×§×¨×”:**
```
×ª××•× ×”: ××§×¨× ×¢× ×”×›×•×ª×¨×ª "××§×¨× ×ª×§×¨×” - ×§×•××” ×‘'"
×ª×•×›×Ÿ: "E Advantage - ×ª×§×¨×” ×—×¦×™ ×©×§×•×¢×” 60X60", "×œ×•×—×•×ª ××™× ×¨×œ×™×", "H=2.80"

×ª×©×•×‘×” × ×›×•× ×”:
{
    "plan_type": "×ª×§×¨×”",
    "confidence": 98,
    "legend_title": "××§×¨× ×ª×§×¨×” - ×§×•××” ×‘'",
    "materials_found": ["×œ×•×—×•×ª ××™× ×¨×œ×™×", "×’×‘×¡", "××¨×§×œ×™×˜"],
    "ceiling_types": [{"code": "E Advantage", "description": "×ª×§×¨×” ×—×¦×™ ×©×§×•×¢×”", "dimensions": "60X60"}],
    "symbols": [{"symbol": "H=2.80", "meaning": "×’×•×‘×” ×ª×§×¨×” 2.80 ××˜×¨"}],
    "notes": "×ª×›× ×™×ª ×ª×§×¨×” ×§×•××” ×‘'"
}
```

**×“×•×’××” 2 - ×§×™×¨×•×ª:**
```
×ª××•× ×”: ××§×¨× ×¢× "×§×™×¨ ×‘×˜×•×Ÿ", "×§×™×¨ ×‘×œ×•×§×™×", "C11, C12"

×ª×©×•×‘×” × ×›×•× ×”:
{
    "plan_type": "×§×™×¨×•×ª",
    "confidence": 95,
    "legend_title": "××§×¨× ×§×™×¨×•×ª",
    "materials_found": ["×‘×˜×•×Ÿ", "×‘×œ×•×§×™×"],
    "symbols": [{"symbol": "C11", "meaning": "×§×•×¨×” ×¡×•×’ 11"}],
    "notes": "×ª×›× ×™×ª ×§×™×¨×•×ª ×•×—×œ×•×§×”"
}
```

**×“×•×’××” 3 - ×¨×™×¦×•×£:**
```
×ª××•× ×”: ××§×¨× ×¢× "×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ 60X60", "××¤×œ×¡ ×’××¨"

×ª×©×•×‘×” × ×›×•× ×”:
{
    "plan_type": "×¨×™×¦×•×£",
    "confidence": 92,
    "legend_title": "××§×¨× ×¨×™×¦×•×£",
    "materials_found": ["×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ", "×§×¨××™×§×”"],
    "symbols": [{"symbol": "F.F.L", "meaning": "Finished Floor Level"}],
    "notes": "×ª×›× ×™×ª ×¨×™×¦×•×£ ×•×’××¨×™×"
}
```

×¢×›×©×™×• × ×ª×— ××ª ×”×ª××•× ×” ×”×–×• ×•×”×—×–×¨ JSON ×‘×œ×‘×“.
"""

    last_error = None
    
    for model in models:
        try:
            message = client.messages.create(
                model=model,
                max_tokens=1000,
                temperature=0.3,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": encoded_image}},
                        {"type": "text", "text": prompt}
                    ]
                }]
            )
            
            response_text = message.content[0].text.strip()
            
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()
            
            if "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                response_text = response_text[start:end]
            
            try:
                result = json.loads(response_text)
                result["_model_used"] = model
                result["_method"] = "few_shot_learning"
                return result
            except json.JSONDecodeError:
                fixed_text = response_text.replace(",]", "]").replace(",}", "}")
                result = json.loads(fixed_text)
                result["_model_used"] = model
                result["_auto_fixed"] = True
                result["_method"] = "few_shot_learning"
                return result
            
        except Exception as e:
            last_error = str(e)
            if "not_found_error" in last_error or "404" in last_error:
                continue
            continue
    
    return {
        "error": f"×›×œ ×”××•×“×œ×™× × ×›×©×œ×•. ×©×’×™××”: {last_error}",
        "tried_models": models
    }

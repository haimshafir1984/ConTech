import os
import base64
import json
try:
    import anthropic
except ImportError:
    anthropic = None
import streamlit as st

def get_anthropic_client():
    """×™×•×¦×¨ ×—×™×‘×•×¨ ×œ-Claude ×‘×¦×•×¨×” ×××•×‘×˜×—×ª ×¢× ×¢×“×™×¤×•×ª ×œ××©×ª× ×™ ×¡×‘×™×‘×”"""
    if anthropic is None:
        return None, "×¡×¤×¨×™×™×ª anthropic ×—×¡×¨×”."
    
    # 1. × ×™×¡×™×•×Ÿ ×œ××©×•×š ×××©×ª× ×™ ×¡×‘×™×‘×” (Render) - ×”×›×™ ×—×©×•×‘
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    
    # 2. ×× ××™×Ÿ, × ×™×¡×™×•×Ÿ ×œ××©×•×š ×-secrets (××§×•××™)
    if not api_key:
        try:
            api_key = st.secrets.get("ANTHROPIC_API_KEY")
        except Exception:
            pass # ×”×ª×¢×œ××•×ª ×× ×”×§×•×‘×¥ ×œ× ×§×™×™×
    
    if not api_key:
        return None, "×—×¡×¨ ××¤×ª×— API"
        
    return anthropic.Anthropic(api_key=api_key), None


def process_plan_metadata(raw_text):
    """××¢×‘×“ ××˜×-×“××˜×” ×©×œ ×ª×•×›× ×™×ª ×¢× × ×™×¡×™×•×Ÿ ××¨×•×‘×” ××•×“×œ×™×"""
    client, error = get_anthropic_client()
    if error: return {}

    # ×¨×©×™××ª ××•×“×œ×™× ×œ× ×™×¡×™×•×Ÿ (××”×—×“×© ×œ×™×©×Ÿ)
    models = [
        "claude-3-5-sonnet-20241022",
        "claude-3-5-sonnet-20240620", 
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307"
    ]

    prompt = f"""
    Analyze construction plan text.
    Input: '''{raw_text[:2000]}'''
    Return JSON with: plan_name, scale (e.g. 1:50), plan_type (construction/demolition/other).
    """

    for model in models:
        try:
            message = client.messages.create(
                model=model,
                max_tokens=500,
                messages=[{"role": "user", "content": prompt}]
            )
            response_text = message.content[0].text
            if "{" in response_text: 
                response_text = "{" + response_text.split("{", 1)[1].rsplit("}", 1)[0] + "}"
            return json.loads(response_text)
        except Exception as e:
            # ×× ×”××•×“×œ ×œ× ×–××™×Ÿ, × ×¡×” ××ª ×”×‘×
            if "not_found_error" in str(e):
                continue
            else:
                # ×©×’×™××” ××—×¨×ª - ×¢×¦×•×¨
                return {}
    
    return {}


def analyze_legend_image(image_bytes):
    """
    ×× ×ª×— ×ª××•× ×” ×©×œ ××§×¨× ×ª×•×›× ×™×ª ×‘× ×™×” ×•××–×”×” ×¡×•×’ ×ª×•×›× ×™×ª ×•×—×•××¨×™×
    ×× ×¡×” ××¡×¤×¨ ××•×“×œ×™× ×¢×“ ×©××—×“ ×¢×•×‘×“
    
    âœ¨ ××©×•×¤×¨: Few-shot learning + ×“×•×’×××•×ª
    """
    client, error = get_anthropic_client()
    if error: return {"error": error}

    # ×¨×©×™××ª ××•×“×œ×™× ×œ× ×™×¡×™×•×Ÿ (××”×—×“×© ×œ×™×©×Ÿ)
    models = [
        "claude-3-5-sonnet-20241022",  # ×”×›×™ ×—×“×©
        "claude-3-5-sonnet-20240620",  # ×’×¨×¡×” ×§×•×“××ª
        "claude-3-opus-20240229",      # Opus (×™×§×¨ ×™×•×ª×¨ ××‘×œ ×˜×•×‘)
        "claude-3-sonnet-20240229",    # Sonnet ×™×©×Ÿ
        "claude-3-haiku-20240307"      # Haiku (×–×•×œ ×•×—×œ×©)
    ]

    encoded_image = base64.b64encode(image_bytes).decode('utf-8')
    
    # âœ¨ ×©×™×¤×•×¨: Few-shot learning ×¢× ×“×•×’×××•×ª
    prompt = """
××ª×” ××•××—×” ×‘× ×™×ª×•×— ×ª×•×›× ×™×•×ª ×‘× ×™×” ×™×©×¨××œ×™×•×ª.
× ×ª×— ××ª ×”××§×¨× (Legend) ×‘×ª××•× ×” ×–×•.

ğŸ“š **×“×•×’×××•×ª ×œ×œ××™×“×”:**

**×“×•×’××” 1 - ×ª×§×¨×”:**
```
×ª××•× ×”: ××§×¨× ×¢× ×”×›×•×ª×¨×ª "××§×¨× ×ª×§×¨×” - ×§×•××” ×‘'"
×ª×•×›×Ÿ: "E Advantage - ×ª×§×¨×” ×—×¦×™ ×©×§×•×¢×” 60X60", "×œ×•×—×•×ª ××™× ×¨×œ×™×", "H=2.80"

×ª×©×•×‘×” × ×›×•× ×”:
{
    "plan_type": "×ª×§×¨×”",
    "confidence": 98,
    "legend_title": "××§×¨× ×ª×§×¨×” - ×§×•××” ×‘'",
    "materials_found": ["×œ×•×—×•×ª ××™× ×¨×œ×™×", "×’×‘×¡", "××¨×§×œ×™×˜"],
    "ceiling_types": [
        {
            "code": "E Advantage",
            "description": "×ª×§×¨×” ×—×¦×™ ×©×§×•×¢×”",
            "dimensions": "60X60"
        }
    ],
    "symbols": [
        {"symbol": "H=2.80", "meaning": "×’×•×‘×” ×ª×§×¨×” 2.80 ××˜×¨"}
    ],
    "notes": "×ª×›× ×™×ª ×ª×§×¨×” ×§×•××” ×‘'"
}
```

**×“×•×’××” 2 - ×§×™×¨×•×ª:**
```
×ª××•× ×”: ××§×¨× ×¢× "×§×™×¨ ×‘×˜×•×Ÿ", "×§×™×¨ ×‘×œ×•×§×™×", "C11, C12, C13"
×ª×•×›×Ÿ: "×§×™×¨ ×‘×˜×•×Ÿ 20 ×¡\"×", "×§×™×¨ ×‘×œ×•×§×™× 10 ×¡\"×", "D14 - ×“×œ×ª"

×ª×©×•×‘×” × ×›×•× ×”:
{
    "plan_type": "×§×™×¨×•×ª",
    "confidence": 95,
    "legend_title": "××§×¨× ×§×™×¨×•×ª",
    "materials_found": ["×‘×˜×•×Ÿ", "×‘×œ×•×§×™×"],
    "symbols": [
        {"symbol": "C11", "meaning": "×§×•×¨×” ×¡×•×’ 11"},
        {"symbol": "D14", "meaning": "×“×œ×ª 80 ×¡\"×"}
    ],
    "notes": "×ª×›× ×™×ª ×§×™×¨×•×ª ×•×—×œ×•×§×”"
}
```

**×“×•×’××” 3 - ×¨×™×¦×•×£:**
```
×ª××•× ×”: ××§×¨× ×¢× "×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ 60X60", "××¤×œ×¡ ×’××¨", "×©×™×¤×•×¢"
×ª×•×›×Ÿ: "××¨×™×— ×§×¨××™", "×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ", "F.F.L +0.00"

×ª×©×•×‘×” × ×›×•× ×”:
{
    "plan_type": "×¨×™×¦×•×£",
    "confidence": 92,
    "legend_title": "××§×¨× ×¨×™×¦×•×£",
    "materials_found": ["×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ", "×§×¨××™×§×”"],
    "symbols": [
        {"symbol": "F.F.L", "meaning": "Finished Floor Level"}
    ],
    "notes": "×ª×›× ×™×ª ×¨×™×¦×•×£ ×•×’××¨×™×"
}
```

---

ğŸ¯ **×¢×›×©×™×• × ×ª×— ××ª ×”×ª××•× ×” ×”×–×•:**

**×¦×¢×“×™× ×œ×–×™×”×•×™:**

1ï¸âƒ£ **×§×¨× ××ª ×”×›×•×ª×¨×ª ×”××¨×›×–×™×ª ×‘××§×¨×**
   - ×—×¤×©: "××§×¨× ×ª×§×¨×”" / "××§×¨× ×§×™×¨×•×ª" / "××§×¨× ×¨×™×¦×•×£"
   - ×–×• ×”×”×•×›×—×” ×”×—×–×§×” ×‘×™×•×ª×¨ ×œ×¡×•×’ ×”×ª×•×›× ×™×ª!

2ï¸âƒ£ **×—×¤×© ××™×œ×•×ª ××¤×ª×— ×¡×¤×¦×™×¤×™×•×ª:**
   
   **×ª×§×¨×” â†’**
   - "×ª×§×¨×” ××§×•×¡×˜×™×ª" / "×ª×§×¨×ª ×’×‘×¡" / "×ª×§×¨×” ×¤×¨×™×§×”"
   - "×œ×•×—×•×ª ××™× ×¨×œ×™×" / "××¨×§×œ×™×˜" 
   - ××™×“×•×ª: "60X60" / "60X120" (××¨×™×—×™ ×ª×§×¨×”)
   - "×ª×œ×™×™×ª ×ª×§×¨×•×ª" / "×¤×¨×•×¤×™×œ×™× × ×•×©××™×"
   
   **×§×™×¨×•×ª â†’**
   - "×§×™×¨ ×‘×˜×•×Ÿ" / "×§×™×¨ ×‘×œ×•×§×™×" / "×§×™×¨ ×§×œ ××©×§×œ"
   - "×¢×•×‘×™ ×§×™×¨" / "×‘×™×“×•×“ ××§×•×¡×˜×™"
   - ×¡×™××•× ×™×: C11, C12, C13 (×§×•×¨×•×ª)
   
   **×¨×™×¦×•×£ â†’**
   - "××¨×™×— ×§×¨××™" / "×’×¨× ×™×˜ ×¤×•×¨×¦×œ×Ÿ" / "×¤×¨×§×˜"
   - "××¤×œ×¡ ×’××¨" / "×©×™×¤×•×¢"
   - ××™×“×•×ª: "30X30" / "60X60" (××¨×™×—×™×)

3ï¸âƒ£ **×‘×“×•×§ ×¡××œ×™× ×•×§×•×“×™×:**
   - C11/C12/C13 â†’ ×§×•×¨×•×ª (×ª×§×¨×”)
   - D14/D17/D18 â†’ ×“×œ×ª×•×ª (×§×™×¨×•×ª)
   - H= â†’ ×’×•×‘×” (×ª×§×¨×”/×§×™×¨×•×ª)

**×¤×•×¨××˜ ×ª×©×•×‘×” - JSON ×‘×œ×‘×“:**
{
    "plan_type": "×ª×§×¨×”",
    "confidence": 95,
    "materials_found": ["×œ×•×—×•×ª ××™× ×¨×œ×™×", "×’×‘×¡", "××¨×§×œ×™×˜"],
    "ceiling_types": [
        {
            "code": "E Advantage",
            "description": "×ª×§×¨×” ×—×¦×™ ×©×§×•×¢×”",
            "dimensions": "60X60"
        }
    ],
    "symbols": [
        {"symbol": "C11", "meaning": "×§×•×¨×” ×¡×•×’ 11"},
        {"symbol": "H=2.80", "meaning": "×’×•×‘×” ×ª×§×¨×” 2.80 ××˜×¨"}
    ],
    "notes": "×ª×›× ×™×ª ×ª×§×¨×” ×§×•××” ×‘'",
    "legend_title": "××§×¨× ×ª×§×¨×”"
}

**×—×©×•×‘ ×××•×“:**
- ×× ×¨×•××” "××§×¨× ×ª×§×¨×”" â†’ plan_type ×—×™×™×‘ ×œ×”×™×•×ª "×ª×§×¨×”" (×‘×™×˜×—×•×Ÿ 98%)
- ×× ×¨×•××” "×œ×•×—×•×ª ××™× ×¨×œ×™×" â†’ ×–×• ×‘×•×•×“××•×ª ×ª×§×¨×”
- ×§×¨× ××ª ×›×œ ×”×˜×§×¡×˜ ×‘×¢×‘×¨×™×ª ×‘×§×¤×™×“×”
- ×”×—×–×¨ **×¨×§** JSON, ××™×Ÿ ×˜×§×¡×˜ × ×•×¡×£
- ×× ×œ× ×‘×˜×•×— ×‘-100%, ×›×ª×‘ confidence × ××•×š (60-70)
- ×”×©×ª××© ×‘×“×•×’×××•×ª ×œ××¢×œ×” ×›××“×¨×™×š!

**×“×•×’×××•×ª:**
âœ… × ×›×•×Ÿ: {"plan_type": "×ª×§×¨×”", "confidence": 98, "legend_title": "××§×¨× ×ª×§×¨×”"}
âŒ ×©×’×•×™: {"plan_type": "××—×¨", "confidence": 80}  â† ×× ×™×© "××§×¨× ×ª×§×¨×”"!
"""

    last_error = None
    
    for model in models:
        try:
            message = client.messages.create(
                model=model,
                max_tokens=1000,  # â† ×”×’×“×œ×ª×™ ×œ-1000 (×™×•×ª×¨ ××§×•× ×œ×“×•×’×××•×ª)
                temperature=0.3,  # â† ×”×•×¨×“×ª×™ temperature ×œ×“×™×•×§
                messages=[{
                    "role": "user",
                    "content": [
                        {
                            "type": "image", 
                            "source": {
                                "type": "base64", 
                                "media_type": "image/png", 
                                "data": encoded_image
                            }
                        },
                        {"type": "text", "text": prompt}
                    ]
                }]
            )
            
            response_text = message.content[0].text.strip()
            
            # × ×™×§×•×™ ×”×ª×©×•×‘×” ×× ×™×© markdown
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()
            
            # × ×™×§×•×™ × ×•×¡×£ - ×—×™×œ×•×¥ ×¨×§ ×”-JSON
            if "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                response_text = response_text[start:end]
            
            # × ×™×¡×™×•×Ÿ ×¨××©×•×Ÿ ×œ×¤×¨×¡×•×¨
            try:
                result = json.loads(response_text)
                result["_model_used"] = model
                result["_method"] = "few_shot_learning"  # âœ¨ ×¡×™××•×Ÿ ×©×–×• ×’×¨×¡×” ××©×•×¤×¨×ª
                return result
            except json.JSONDecodeError as json_err:
                # × ×™×¡×™×•×Ÿ ×œ×ª×§×Ÿ ×©×’×™××•×ª × ×¤×•×¦×•×ª
                fixed_text = response_text
                fixed_text = fixed_text.replace(",]", "]")  # ×¤×¡×™×§ ××™×•×ª×¨ ×œ×¤× ×™ ]
                fixed_text = fixed_text.replace(",}", "}")  # ×¤×¡×™×§ ××™×•×ª×¨ ×œ×¤× ×™ }
                
                try:
                    result = json.loads(fixed_text)
                    result["_model_used"] = model
                    result["_auto_fixed"] = True
                    result["_method"] = "few_shot_learning"
                    return result
                except:
                    # × ×›×©×œ - × ×©××•×¨ ××ª ×”×©×’×™××” ×•× ××©×™×š ×œ××•×“×œ ×”×‘×
                    last_error = f"JSON Error: {str(json_err)} | Response: {response_text[:200]}"
                    continue
            
        except Exception as e:
            error_str = str(e)
            last_error = error_str
            
            # ×× ×”××•×“×œ ×œ× × ××¦× (404), × ×¡×” ××ª ×”×‘×
            if "not_found_error" in error_str or "404" in error_str:
                continue
            
            # ×©×’×™××” ××—×¨×ª - × ×¡×” ××ª ×”××•×“×œ ×”×‘×
            continue
    
    # ×× ×”×’×¢× ×• ×œ×›××Ÿ - ×›×œ ×”××•×“×œ×™× × ×›×©×œ×•
    return {
        "error": f"×›×œ ×”××•×“×œ×™× × ×›×©×œ×•. ×©×’×™××” ××—×¨×•× ×”: {last_error}",
        "tried_models": models,
        "_fallback_suggestion": "× ×¡×” ×œ×—×ª×•×š ××ª ×”××§×¨× ×™×“× ×™×ª ×•×œ× ×¡×•×ª ×©×•×‘"
    }
